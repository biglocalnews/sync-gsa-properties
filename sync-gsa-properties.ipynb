{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decac317",
   "metadata": {},
   "source": [
    "# API sync demonstration\n",
    "\n",
    "This program syncs U.S. General Service Administration lease and property\n",
    "holding records from a federal API to a local drive, then syncs them with\n",
    "Big Local News' server using BLN's API.\n",
    "\n",
    "This is not a complex program, but is intended to show how easy it is to build things.\n",
    "\n",
    "We start with bringing in some required modules.\n",
    "\n",
    "The `bln` client itself is helpful.\n",
    "\n",
    "`requests` is a rather common module used to, among other things,\n",
    "download files. It can do a lot more.\n",
    "\n",
    "The rest are internal Python parts: `datetime` for calculating dates;\n",
    "`json` for reading JSON-formatted data files;\n",
    "`os` for doing some things with the operating system, like creating directories;\n",
    "and `sys`, which here we use just to quit the Python program if we don't need to do anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f909300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bln.client import Client\n",
    "import requests\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ada632",
   "metadata": {},
   "source": [
    "## API preparation\n",
    "\n",
    "Next, we're going to retrieve the credentials for the APIs.\n",
    "That's an abbreviation for the Application Programming Interface,\n",
    "which ... is a lot to say. But it's basically a defined way for\n",
    "one computer to do stuff with another computer -- retrieve information,\n",
    "upload file, get a listing of projects, all stuff like that.\n",
    "\n",
    "A lot of the work you want to do will typically involve several\n",
    "API calls to bring it all together, in the same way few recipes\n",
    "are just one step.\n",
    "\n",
    "To request a federal API key, visit https://api.data.gov/signup/\n",
    "if that link still works. Things were ... changing ... quickly in\n",
    "early 2025.\n",
    "\n",
    "Big Local News has instructions on getting an API key for their\n",
    "service at https://bln-python-client.readthedocs.io/en/latest/gettingstarted.html#setup ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573bae22",
   "metadata": {},
   "outputs": [],
   "source": [
    "bln_api = os.environ[\"BLN_API_TOKEN\"]     # A consistent naming scheme is the hobgoblin of little minds\n",
    "fed_api = os.environ[\"DATA_DOT_GOV\"]\n",
    "\n",
    "sync_log_file = \"sync-log.json\"\n",
    "\n",
    "data_dir = \"data/\"\n",
    "os.makedirs(data_dir, exist_ok=True)      # Create the data directory if it doesn't already exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2805514d",
   "metadata": {},
   "source": [
    "Let's build a couple functions to make the code somewhat more readable, though this code has plenty of problems remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a92233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_log():\n",
    "    global sync_log_file\n",
    "    if not os.path.exists(sync_log_file):\n",
    "        local_log = {}\n",
    "        print(f\"No log data found.\")\n",
    "    else:\n",
    "        with open(sync_log_file, \"r\", encoding=\"utf-8\") as infile:\n",
    "            local_log = json.load(infile)\n",
    "            print(f\"{len(local_log):,} log entries found.\")\n",
    "    return(local_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bac29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_log(local_log):\n",
    "    global sync_log_file\n",
    "    with open(sync_log_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(json.dumps(local_log, indent=4*\" \"))\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa03dac",
   "metadata": {},
   "source": [
    "## Get needed data from Big Local News' API\n",
    "\n",
    "We use the BLN API key to create an instance of BLN's client. That's just one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08670ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bln = Client(bln_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a02c9d2",
   "metadata": {},
   "source": [
    "We need to look up the project and then pull information from it.\n",
    "\n",
    "This builds out a dictionary of filenames and a timestamp for when the files\n",
    "last changed. The update time is helpful for logging and analysis, potentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf032831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GSA project.\n",
    "project = bln.get_project_by_name(\"GSA leases and properties\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad694e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files in the project.\n",
    "archived_files = {}\n",
    "for f in project['files']:\n",
    "    archived_files[f['name']] = f['updatedAt']\n",
    "print(f\"{len(archived_files):,} archived files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5dab37",
   "metadata": {},
   "source": [
    "## Pull information from GSA\n",
    "\n",
    "This next part is just one line but it took a bit of effort.\n",
    "\n",
    "The landing page for some of this stuff no longer had a link\n",
    "to get an API key, and crucial parts of the documentation had\n",
    "to be kind of analyzed.\n",
    "\n",
    "The data.gov index isn't actually at www.data.gov or \n",
    "api.data.gov. The API is accessed through ...\n",
    "catalog.data.gov.\n",
    "\n",
    "The API follows the CKAN standard, except you have to change\n",
    "the hostname, the computer part of it. For example, to see\n",
    "what files are associated with a collection, you can hit the\n",
    "docs at https://docs.ckan.org/en/2.10/api/index.html#get-able-api-functions\n",
    "    \n",
    "Right near the top it describes the `package_show` call. So rewriting\n",
    "the example a little, and finding the GSA owned and leased properties\n",
    "link in data.gov, we can write a single line to get a JSON-formatted\n",
    "collection of details of that package, including the filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(\"https://catalog.data.gov/api/3/action/package_show?id=inventory-of-owned-and-leased-properties-iolp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e050be",
   "metadata": {},
   "source": [
    "## Bringing pieces together\n",
    "\n",
    "Now we have identified the files that Big Local News has through its API.\n",
    "We have details that include the filenames through the data.gov API.\n",
    "\n",
    "In this case, there's something handy -- the regular files for the GSA\n",
    "appear to be released each week, with prefixes like `2025-2-7` and\n",
    "`2025-1-31`. They've already published a version number, you see.\n",
    "\n",
    "In this case, we just need to check to see if the GSA site has any files\n",
    "the BLN site doesn't have. If it does, we can fetch them to our own\n",
    "computer, then pass them back to BLN.\n",
    "\n",
    "The GSA stuff is viewable within the JSON, in a result:resources\n",
    "section. Our call to `r/requests` here allows us to treat the download\n",
    "as JSON and convert it into a Python-friendly object instantly.\n",
    "\n",
    "So let's look at each GSA file and see if it exists on the BLN site;\n",
    "if not, we need to add it to a to-do list or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cca2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "additions = []\n",
    "downloaded_files = {}\n",
    "\n",
    "catalog_entries = r.json()['result']['resources']\n",
    "\n",
    "for catalog_entry in catalog_entries:\n",
    "    remoteurl = catalog_entry['url']\n",
    "    remotefilename = remoteurl.split(\"/\")[-1]\n",
    "    if remotefilename not in archived_files:\n",
    "        additions.append(catalog_entry)\n",
    "        downloaded_files[remotefilename] = False\n",
    "print(f\"{len(additions):,} new entries found among {len(catalog_entries):,} source files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c284b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.isoformat(datetime.datetime.now(datetime.timezone.utc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d47e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data = fetch_log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd101d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_data[timestamp] = {\n",
    "    \"additions\": additions,\n",
    "    \"downloaded_files\": downloaded_files,\n",
    "    \"archived_files\": archived_files,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8057b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log(log_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddf367",
   "metadata": {},
   "source": [
    "## We might be done ... ?\n",
    "\n",
    "If we have no additions to process, there's nothing left to download.\n",
    "We've already updated the log file with our latest effort and we\n",
    "can just quit, in that case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105edc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(additions) == 0:\n",
    "    print(\"No new records found. Stopping.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779e907",
   "metadata": {},
   "source": [
    "## But if we weren't done ...\n",
    "\n",
    "All the work above here has been just to identify if we have\n",
    "new files to process. If we've reached this point,\n",
    "`additions` has at least one new file for us to download.\n",
    "Everything has built up to this.\n",
    "\n",
    "Fortunately, it's pretty darn easy to download from GSA\n",
    "and then upload to BLN. (It's even possible to not download\n",
    "the file to the local computer, but that's ugly and looks\n",
    "more confusing and also local copies are good, actually.)\n",
    "\n",
    "So in this case we're looking at our additions, finding\n",
    "the base filename, and trying to download it to our computer.\n",
    "\n",
    "If the download process is successful, we then send it to\n",
    "Big Local News. If that's succeessful, we update the\n",
    "in-memory log and later save it. And then we're truly done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c06d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(additions):,} new records found.\")\n",
    "project_id = project['id']\n",
    "for addition in additions:\n",
    "    remoteurl = addition['url']\n",
    "    basefilename = remoteurl.split(\"/\")[-1]\n",
    "    targetfilename = data_dir + basefilename\n",
    "    print(f\"Trying to fetch {remoteurl} to {targetfilename}.\")\n",
    "    r = requests.get(remoteurl)\n",
    "    if not r.ok:\n",
    "        print(f\"Error downloading {remoteurl} to {targetfilename}.\")\n",
    "    else:\n",
    "        with open(targetfilename, \"wb\") as outfile:\n",
    "            outfile.write(r.content)\n",
    "        print(f\"Trying to send {basefilename} to Big Local News.\")\n",
    "        bln.upload_file(project_id, targetfilename)\n",
    "        log_data[timestamp][\"downloaded_files\"][basefilename] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a241e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_log(log_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
